#!/bin/bash
#!/usr/bin/env bash

# Copyright 2020 - Remy van Elst - https://raymii.org/s/software/Bash_HTTP_Monitoring_Dashboard.html
# Copyright 2021 - Silvano Zampardi
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Afferro General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

########################################################################
# Start of configuration.
declare -A MONITOR_URLS=(
	["github.com"]="https://github.xcom"
)
# The default status code. Can be overridden per URL lower in the script.
defaultExpectedStatusCode=200

# Expected code for url, key must match MONITOR_URLS[]. Only for URL's you consider UP, but for example require authentication
declare -A URL_STATUSCODES=(
	#	["github.com"]=200
)
# How many curl checks to run at the same time
maxConcurrentCURLs=12

# Max timeout of a check in seconds
defaultTimeOut=10

# After how many seconds should we re-check any failed checks? (To prevent flapping)
flapRetry=5

# Title of the webpage
title="Status Dashboard"

# Use CGI mode
cgi=false

# Alert
sendAlerts="${sendAlerts:-0}"

# Callback URL for failed checks. Script will do a POST request with
# the following parameters: url, name, expected_status, actual_status, error.
callbackURL=""

########################################################################

# function definitions

# check if command exists and fail otherwise
command_exists() {
	for _i in "${@}"; do
		if ! command -v "${_i}" >/dev/null 2>&1; then
			printf 'Required dependency [%s] is not installed. Aborting.\n' "${_i}"
			exit 1
		fi
	done
}

# environment checks
command_exists curl jq
if [[ ${BASH_VERSINFO:-0} -lt 4 ]]; then
	printf 'Bash version =>4 required. Aborting.\n' >&2
	exit 2
fi

case "$(uname -s)" in
	Darwin*)
		datecmd="$(command -v gdate)"
		command_exists "${datecmd}"
		;;
	*) datecmd="$(command -v date)" ;;
esac

# start of the function definitions

# This function allows the script to execute all the curl calls in parallel.
# Otherwise, if one would timeout or take long, the rest after that would be
# slower. We're writing the status code to a file, reading that later on. Why?
# Because an array cannot be filled via a subprocess (curl ... &)
doRequest() {
	local name="${1}"
	local url="${2}"
	local expectedStatusCode="${defaultExpectedStatusCode}"
	# check if there is a specific status code for this domain
	if [[ -n ${URL_STATUSCODES["${name}"]} ]]; then
		expectedStatusCode=${URL_STATUSCODES["${name}"]}
	fi
	# epoch in microseconds, but last chars stripped so it's milliseconds
	local checkStartTimeMs=$("${datecmd}" '+%s%3N')
	# do the check
	local checkStatusCode=$(curl --max-time "${defaultTimeOut}" --silent --show-error --insecure --output /dev/null --write-out "%{http_code}" --stderr "${tempfolder}/FAIL/${name}.error" "${url}")
	local checkEndTimeMs=$("${datecmd}" '+%s%3N')
	local timeCheckTook=$((checkEndTimeMs - checkStartTimeMs))
	case "${checkStatusCode}" in
		"${expectedStatusCode}")
			printf '%s' "${timeCheckTook}" >"${tempfolder}"/OK/"${name}".duration
			# remove any previous failed check attempt
			if [[ -r "${tempfolder}/FAIL/${name}.status" ]]; then
				rm "${tempfolder}/FAIL/${name}.status"
			fi
			;;
		*)
			printf '%d' "${checkStatusCode}" >"${tempfolder}"/FAIL/"${name}".status
			# remove any previous okay check
			if [[ -r "${tempfolder}"/OK/"${name}".duration ]]; then
				rm "${tempfolder}"/OK/"${name}".duration
			fi
			;;
	esac
	# if the error file is empty, remove it.
	if [[ ! -s "${tempfolder}"/FAIL/"${name}".error ]]; then
		rm "${tempfolder}"/FAIL/"${name}".error
	fi
}

recheckFailedChecks() {
	local -a failFiles=("${tempfolder}"/FAIL/*.status)
	if [[ ${#failFiles[@]} -gt 0 ]]; then
		printf 'Failed checks, re-checking after %ds ..' "${flapRetry}" 1>&2
		sleep "${flapRetry}"
		for _f in "${failFiles[@]}"; do
			if [[ ! -r ${_f} ]]; then continue; fi
			local filenameWithoutExt=${_f%.*}
			local _name="$(basename "${filenameWithoutExt}")"
			if [[ "$(jobs -p | wc -l)" -ge ${maxConcurrentCURLs} ]]; then
				wait -n
			fi
			doRequest "${_name}" "${MONITOR_URLS["${_name}"]}"
		done
		wait
	fi
}

writeOkayChecks() {
	printf '</div></div>\n<div class=row><div class=col>\n'
	local -a okFiles=("${tempfolder}"/OK/*.duration)
	for _f in "${okFiles[@]}"; do
		if [[ -r ${_f} ]]; then
			printf '<a href="#" class="btn btn-success disabled" tabindex="-1" role="button" aria-disabled="true" style="margin-top: 10px; padding: 10px;"> %s\n<font color=LightGray> (%dms)\n</font>\n</a> &nbsp;\n' "$(basename "${_f%.*}")" "$(<"${_f}")"
		fi
	done
}

doCallbackForFailedChecks() {
	# If the callback URL is empty, don't do anything.
	if [[ -z ${callbackURL} ]] && [[ ${sendAlerts} == 0 ]]; then
		return
	fi
	local -a failFiles=("${tempfolder}"/FAIL/*.status)
	for _f in "${failFiles[@]}"; do
		if [[ ! -r ${_f} ]]; then continue; fi
		local filenameWithoutExt="$(basename "${_f%.*}")"
		local _name="$(basename "${filenameWithoutExt}")"
		local curlError="Status code does not match expected code"
		if [[ -r "${tempfolder}/FAIL/${filenameWithoutExt}".error ]]; then
			curlError="$(<"${tempfolder}"/FAIL/"${filenameWithoutExt}".error)"
		fi
		local url="${MONITOR_URLS["${filenameWithoutExt}"]}"
		local currentStatus="$(<"${_f}")"
		local expectedStatus="${defaultExpectedStatusCode}"
		if [[ -n ${URL_STATUSCODES["${_name}"]} ]]; then
			expectedStatus="${URL_STATUSCODES["${_name}"]}"
		fi
		if [[ -n ${callbackURL} ]]; then
			jq -cM \
				--arg url "${url}" \
				--arg name "${filenameWithoutExt}" \
				--arg expected_status "${expectedStatus}" \
				--arg actual_status "${currentStatus}" \
				--arg error "${curlError}" \
				'{ url: $url, name: $name, expected_status: $expected_status, actual_status: $actual_status, error: $error }' |
				curl \
					--insecure --show-error \
					--max-time "${defaultTimeOut}" --retry 4 \
					--silent --output /dev/null \
					-H "Content-Type: application/json" \
					--data @- \
					"${callbackURL}"
		fi
		if [[ ${sendAlerts} != 0 ]]; then
			printf -v _message '*WARNING*: [`%s`] healthcheck (`%s`) failed\nHTTP code / expected: *%d / %d*\nError: `%s`\n' "${_name}" "${MONITOR_URLS["${_name}"]}" "${currentStatus}" "${expectedStatus}" "${curlError}"
			/usr/local/bin/rocketchat-post -e ":warning:" "${_message}" &
		fi
	done
}

writeFailedChecks() {
	local -a failFiles=("${tempfolder}"/FAIL/*.status)
	local failCount=${#failFiles[@]}
	if [[ failCount -gt 0 ]]; then
		printf '<div class="alert alert-danger" role="alert">\nErrors occured! %d check(s) have failed.\n</div>\n<table class="table">\n<thead><tr>\n<th>Name</th>\n<th>HTTP Status/Expected</th>\n<th>Error</th>\n</tr></thead><tbody>\n' "${failCount}"
		for _f in "${failFiles[@]}"; do
			if [[ ! -r ${_f} ]]; then continue; fi
			local filenameWithoutExt=${_f%.*}
			local _name="$(basename "${filenameWithoutExt}")"
			local curlError="Status code does not match expected code"
			if [[ -r "${filenameWithoutExt}".error ]]; then
				curlError="$(<"${filenameWithoutExt}".error)"
			fi
			local status="$(<"${_f}")"
			printf '<tr class="table-danger"><td>%s\n</td><td>\n' "${_name}"
			local expectedStatus="${defaultExpectedStatusCode}"
			if [[ -n ${URL_STATUSCODES["${_name}"]} ]]; then
				expectedStatus="${URL_STATUSCODES["${_name}"]}"
			fi
			printf '%d / %d\n' "${status}" "${expectedStatus}"
			printf '</td><td>%s\n</td></tr>\n' "${curlError}"
		done
		printf '<tr><td colspan=3 class="small">All failed checks were attempted again after %ds and failed again.</td></tr>\n</tbody></table>\n' "${flapRetry}"
	else
		printf '<div class="alert alert-success" role="alert">\nAll is well, all %d services are up.\n</div>' "${#MONITOR_URLS[@]}"
	fi
}

writeHeader() { printf '<!doctype html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="refresh" content="60"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">\n<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">\n<title>%s</title>\n</head><body>\n<div class=container><div class=row><div class=col>\n<h1>%s</h1>\n</div></div>\n<div class=row><div class=col>\n' "${title}" "${title}"; }
writeFooter() { printf '</div></div>\n<br>\n<div class=row><div class=col>\n<p class=small>Last check: %s \n<br>Total duration: %dms\n</p>\n</div></div></div>\n</body></html>\n' "$(date -u)" "${runtime}"; }

########################################################################

# script start

# Exit immediately if a command exits with a non-zero status.
set -eo pipefail
# patterns which match no files expand to a null string, otherwise later on we'd have *.status as a file...
shopt -s nullglob

if [[ ${cgi} == true ]]; then
	printf 'Content-type: text/html\n'
fi

# Total script duration timer
start=$("${datecmd}" '+%s%3N')

# try to create folders, if it fails, stop the script.
declare -x tempfolder="$(mktemp -d 2>/dev/null || printf '/tmp/statusmon')"
mkdir -p "${tempfolder}"/{FAIL,OK} || exit 1
# Cleanup the status files at exit
trap 'rm -fr "${tempfolder}"/{FAIL,OK}' EXIT

# Do the checks parallel
for key in "${!MONITOR_URLS[@]}"; do
	value="${MONITOR_URLS["${key}"]}"
	if [[ "$(jobs -p | wc -l)" -ge ${maxConcurrentCURLs} ]]; then # run 12 curl commands at max parallel
		wait -n
	fi
	doRequest "${key}" "${value}" &
done
wait

# Re-check any failed checks to prevent flapping
recheckFailedChecks

# header
writeHeader

# Failed checks, if any, go on top
writeFailedChecks

# Okay checks go below the failed checks
writeOkayChecks

# stop the total timer
end=$("${datecmd}" '+%s%3N')
runtime=$((end - start))

writeFooter

# Execute the callback for any failed URL's
doCallbackForFailedChecks
